{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOeqSQj4BW04KRI+N4s4K7u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obinnachike/Llama2-with-LangChain/blob/main/Llama2_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI6fgnjKKAmL"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ],
      "metadata": {
        "id": "7FRL9A4TKJqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "NLAO8a5SL1nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**03: Import All the Required Libraries**"
      ],
      "metadata": {
        "id": "77eVo4DhKqtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "SXYZcFPlLOv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "0KYnwqNtKqRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoTokenizer. A tokenizer is responsible for preprocessing text into an array of numbers as inputs to a model.\n"
      ],
      "metadata": {
        "id": "jI9KrbmmLdZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "qYFD8k6sKi-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "wT1KJjVcLjYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "vISWYfe0MpBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "g5TR9HvcMrlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model=\"meta-llama/Llama-2-7b-chat-hf\"\n",
        "model=\"daryl149/llama-2-7b-chat-hf\""
      ],
      "metadata": {
        "id": "wlIznoiSMuwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained(model)"
      ],
      "metadata": {
        "id": "o1WT8f27NZkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline=transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    max_length=1000,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        "    )"
      ],
      "metadata": {
        "id": "aHj1ohyaNlzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature':0})"
      ],
      "metadata": {
        "id": "MmFNZsZvRgCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"What would be a good name for a company that makes colorful socks\""
      ],
      "metadata": {
        "id": "jOO5C0k7OAPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(prompt))"
      ],
      "metadata": {
        "id": "Ce41K3aaP3e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"What would be a good name for a company that makes colorful socks\""
      ],
      "metadata": {
        "id": "psUdUYb3P6We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(prompt))"
      ],
      "metadata": {
        "id": "goMoRdagRqEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"I want to open a restaurant for  indian food. Suggest me a fence name for this\""
      ],
      "metadata": {
        "id": "X_NlAnd8RsLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(prompt))"
      ],
      "metadata": {
        "id": "yzGn50I9RzgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**05: Prompt Templates**"
      ],
      "metadata": {
        "id": "fx1xWIrZR6WF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently in the above applications we are writing an entire prompt, if you are creating a user directed application then this is not an ideal case\n",
        "\n",
        "LangChain faciliates prompt management and optimization.\n",
        "\n",
        "Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and construct a prompt, and only then send that to the LLM."
      ],
      "metadata": {
        "id": "0uSwwtOnR-Ql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In many Large Language Model applications we donot pass the user input directly to the Large Language Model, we add the user input to a large piece of text called prompt template"
      ],
      "metadata": {
        "id": "hpLnIOv_SFOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import All the Required Libraries"
      ],
      "metadata": {
        "id": "TrI276AhSJ4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "HWnwys7hR2EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "1wNDTwtCSM-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template1=PromptTemplate(input_variables=[\"cuisine\"],\n",
        "                               template=\"I want to open a restaurant for {cuisine} food. Suggest a fency name for this\")"
      ],
      "metadata": {
        "id": "8X8ASE6QSQCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_prompt=prompt_template1.format(cuisine=\"indian\")"
      ],
      "metadata": {
        "id": "Zm2DAVB9SU3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_prompt)"
      ],
      "metadata": {
        "id": "Zdv77oWZSdVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template2=PromptTemplate(input_variables=[\"book_name\"],\n",
        "                               template=\"Provide me a concise summary of the book {book_name}\")"
      ],
      "metadata": {
        "id": "gYbV2Hs7Sgwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_prompt=prompt_template2.format(book_name=\"Alchemist\")"
      ],
      "metadata": {
        "id": "3I_vfHVcS2W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_prompt)"
      ],
      "metadata": {
        "id": "P9EUAFlTS52v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template2, verbose=True)\n",
        "response= chain.run(\"Harry Potter\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "xGx_nIYWS8V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2LduQ-WTTspy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}